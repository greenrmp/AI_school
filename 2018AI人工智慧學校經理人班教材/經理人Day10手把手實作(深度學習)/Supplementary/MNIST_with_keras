{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_with_keras","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1fgswM65Ee3U9V1bRt8PrAZvCAZfryW8I","timestamp":1523122901524}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Av24Tb1XUILH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"9f098a5a-b1c7-4c18-fe56-131e683fc35c","executionInfo":{"status":"ok","timestamp":1523621449302,"user_tz":-480,"elapsed":5328,"user":{"displayName":"游為翔","photoUrl":"//lh3.googleusercontent.com/-LG6Of8zGKwQ/AAAAAAAAAAI/AAAAAAAAADU/X3DK7lclees/s50-c-k-no/photo.jpg","userId":"106237220959659905188"}}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","!pip install -q keras\n","import keras\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Dense, Activation\n","from keras.optimizers import SGD\n","import keras.backend as K"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"Oqlr5migUILd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":575},"outputId":"b884a902-3174-4918-e21e-64a4f500b786"},"cell_type":"code","source":["#@title Run the model with BP method { vertical-output: true }\n","large_mnist = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","addition_hidden_units = None #@param {type:\"raw\"}\n","# addition_hidden_units should be None or list of hidden_units\n","\n","if large_mnist:\n","  # Load data from tensorflow MNIST dataset, which image size is 28 x 28 \n","  from tensorflow.examples.tutorials.mnist import input_data\n","  mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n","  x_ = mnist.train.images\n","  y_ = mnist.train.labels\n","  batch_size = 100\n","  epochs = 10\n","  \n","else:\n","  # Load data from sklearn MNIST (digit) dataset, which image size is 8 x 8\n","  from sklearn.datasets import load_digit\n","  digits = load_digits()\n","  x_, y_single = digits.data, digits.target\n","  \n","  # do some data preprocessing\n","  y_ = np.zeros((len(y_single), 10))\n","  y_[np.arange(len(y_)), y_single] = 1\n","  batch_size = 36\n","  epochs = 10\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","x_ = x_ / x_.max() # normailze it to 0 - 1\n","\n","# do train_test split\n","x_train, x_test, y_train, y_test = train_test_split(x_, y_, test_size = 0.1, stratify = y_)\n","\n","K.clear_session()\n","model = Sequential()\n","\n","model.add(Dense(25, activation='sigmoid', input_shape=(x_.shape[-1],)))\n","\n","if addition_hidden_units is None:\n","  pass\n","else:\n","  for i_hidden in addition_hidden_units:\n","    model.add(Dense(i_hidden, activation='sigmoid') )\n","\n","model.add(Dense(y_.shape[-1], activation='softmax'))\n","model.summary()\n","\n","optim = SGD(lr=0.1)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer= optim,\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_, y_, \n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","\n","\n","train_loss = history.history.get('loss')\n","train_acc = history.history.get('acc')\n","valid_loss = history.history.get('val_loss')\n","valid_acc = history.history.get('val_acc')\n","\n","train_loss = history.history.get('loss')\n","train_acc = history.history.get('acc')\n","valid_loss = history.history.get('val_loss')\n","valid_acc = history.history.get('val_acc')\n","\n","\n","plt.plot(np.arange(len(train_loss)), train_loss, 'b-', label = 'train')\n","plt.plot(np.arange(len(valid_loss)), valid_loss, 'r-', label = 'valid')\n","plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","plt.show()\n","\n","plt.plot(np.arange(len(train_acc)), train_acc, 'b-', label = 'train')\n","plt.plot(np.arange(len(valid_acc)), valid_acc, 'r-', label = 'valid')\n","plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 25)                19625     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                260       \n","=================================================================\n","Total params: 19,885\n","Trainable params: 19,885\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 55000 samples, validate on 5500 samples\n","Epoch 1/10\n","55000/55000 [==============================] - 1s 27us/step - loss: 1.1097 - acc: 0.7687 - val_loss: 0.6010 - val_acc: 0.8607\n","Epoch 2/10\n","55000/55000 [==============================] - 1s 26us/step - loss: 0.4936 - acc: 0.8813 - val_loss: 0.4235 - val_acc: 0.8896\n","Epoch 3/10\n","36300/55000 [==================>...........] - ETA: 0s - loss: 0.3981 - acc: 0.8969"],"name":"stdout"},{"output_type":"stream","text":["55000/55000 [==============================] - 1s 25us/step - loss: 0.3905 - acc: 0.8977 - val_loss: 0.3624 - val_acc: 0.9018\n","Epoch 4/10\n","55000/55000 [==============================] - 1s 25us/step - loss: 0.3450 - acc: 0.9054 - val_loss: 0.3278 - val_acc: 0.9082\n","Epoch 5/10\n","55000/55000 [==============================] - 1s 26us/step - loss: 0.3173 - acc: 0.9122 - val_loss: 0.3050 - val_acc: 0.9129\n","Epoch 6/10\n","49500/55000 [==========================>...] - ETA: 0s - loss: 0.2971 - acc: 0.9172"],"name":"stdout"}]}]}